# ğŸ§  AI RAG Chatbot Backend  
**Memory â€¢ Retrieval-Augmented Generation (RAG) â€¢ FastAPI â€¢ LangChain â€¢ Vector DB**

---

## ğŸ“Œ Project Overview

This project implements an **enterprise-grade backend for a Conversational AI Chatbot** using **FastAPI** and **LangChain**.

The chatbot supports:

- âœ… Session-based conversational memory
- âœ… Retrieval Augmented Generation (RAG) using PDFs
- âœ… Vector search using ChromaDB
- âœ… Source citations with answers
- âœ… Extensible architecture (Auth, Streaming, Tools ready)

---

## ğŸ—ï¸ Architecture

Client â†’ FastAPI â†’ LangChain (Memory + RAG) â†’ ChromaDB â†’ Documents

---

## ğŸ§° Tech Stack

- FastAPI  
- LangChain (classic + openai)  
- OpenAI  
- ChromaDB  
- PyPDF  
- Uvicorn  
- Python 3.10+  

---

## ğŸ“ Folder Structure

```
ai_rag_chatbot_backend/
â”œâ”€â”€ app.py
â”œâ”€â”€ config.py
â”œâ”€â”€ database.py
â”œâ”€â”€ models.py
â”œâ”€â”€ auth/
â”œâ”€â”€ memory/
â”œâ”€â”€ rag/
â”œâ”€â”€ tools/
â”œâ”€â”€ analytics/
â”œâ”€â”€ streaming/
â”œâ”€â”€ utils/
â”œâ”€â”€ data/
â”œâ”€â”€ vectorstore/
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

## ğŸ” Environment Variables

Create a `.env` file:

```
OPENAI_API_KEY=your_openai_api_key_here
CHROMA_PERSIST_DIR=vectorstore
```

---

## â–¶ï¸ Step-by-Step Setup

### 1ï¸âƒ£ Create Virtual Environment

```
python -m venv venv
venv\Scripts\activate
```

### 2ï¸âƒ£ Install Dependencies

```
pip install fastapi uvicorn pydantic python-dotenv langchain langchain-classic langchain-openai langchain-community chromadb pypdf
```

### 3ï¸âƒ£ Add PDFs

Place PDFs inside:
```
data/
```

### 4ï¸âƒ£ Ingest Documents

```
python rag/ingest.py
```

### 5ï¸âƒ£ Run Server

```
uvicorn app:app --reload
```

Open:
```
http://127.0.0.1:8000/docs
```

---

## ğŸ§ª Test API

POST `/chat`

```
{
  "message": "What is RAG?",
  "session_id": "test-1",
  "memory_type": "buffer"
}
```

---
